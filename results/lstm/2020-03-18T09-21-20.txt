Model Type: LSTM
Dataset: WikiSyntheticGeneral



SAMPLES
Total               |Training            |Validation          |Test                
914                 |640                 |137                 |137                 


DATA PROCESS CONFIGURATION
Tokenizer           |Embeddings          |Vocabulary                              
split               |glove               |built (size: 8897)                      


TRAIN CONFIGURATION
Epochs              |Learn Rate          |Batch Size          |Hidden Size         
5                   |0.001               |32                  |256                 


SCORES
Train Acc           |Val Acc             |Test Acc            
83.12               |83.12               |83.12               


GRAPH DATA
{"loss": [0.6939970850944519, 0.6890696287155151, 0.704226016998291, 0.7028608918190002, 0.6832743287086487, 0.700819730758667, 0.6945264935493469, 0.6913803219795227, 0.685555636882782, 0.6813492178916931, 0.6935033798217773, 0.6823407411575317, 0.6772708296775818, 0.6858283877372742, 0.6533333659172058, 0.669103741645813, 0.6314026713371277, 0.6314427256584167, 0.4986379146575928, 0.602923572063446, 0.41708752512931824, 0.5031159520149231, 0.6545482277870178, 0.6324051022529602, 0.6084479689598083, 0.5746872425079346, 0.5537426471710205, 0.49027252197265625, 0.6093153357505798, 0.5626174807548523, 0.6022629737854004, 0.5599215626716614, 0.6221051216125488, 0.630402147769928, 0.6442615985870361, 0.6000325679779053, 0.6170830130577087, 0.5151801109313965, 0.5153023600578308, 0.5011807680130005, 0.48862484097480774, 0.7452556490898132, 0.41900089383125305, 0.5251410007476807, 0.5118815898895264, 0.6505429744720459, 0.6036691069602966, 0.5543306469917297, 0.6543316841125488, 0.653922438621521, 0.6387799382209778, 0.5102701783180237, 0.5408254861831665, 0.5875349640846252, 0.5690819025039673, 0.5235710144042969, 0.6192328333854675, 0.4859716594219208, 0.535167932510376, 0.5020620226860046, 0.4454983174800873, 0.6221190094947815, 0.4405362010002136, 0.4931715726852417, 0.47417116165161133, 0.3504382073879242, 0.44417935609817505, 0.4683396518230438, 0.5312770009040833, 0.1795133650302887, 0.6416212916374207, 0.6450796723365784, 0.5861701369285583, 0.41030052304267883, 0.32954180240631104, 0.4709028899669647, 0.44886156916618347, 0.44945767521858215, 0.5150494575500488, 0.27383553981781006, 0.43766722083091736, 0.3197430372238159, 0.3567904829978943, 0.5072486996650696, 0.3482077717781067, 0.4564134478569031, 0.4278629720211029, 0.42375439405441284, 0.5202949643135071, 0.36279556155204773, 0.32542356848716736, 0.29619988799095154, 0.45793840289115906, 0.25499749183654785, 0.5186874866485596, 0.3029821813106537, 0.32991722226142883, 0.3813474178314209, 0.463373064994812, 0.3205999732017517], "acc": [46.875, 59.375, 34.375, 40.625, 68.75, 34.375, 50.0, 68.75, 53.125, 59.375, 53.125, 59.375, 53.125, 50.0, 62.5, 50.0, 65.625, 59.375, 75.0, 84.375, 90.625, 71.875, 65.625, 71.875, 68.75, 68.75, 68.75, 81.25, 59.375, 75.0, 62.5, 71.875, 62.5, 56.25, 53.125, 75.0, 71.875, 90.625, 96.875, 84.375, 84.375, 71.875, 90.625, 75.0, 78.125, 56.25, 68.75, 59.375, 56.25, 56.25, 50.0, 71.875, 68.75, 68.75, 65.625, 78.125, 65.625, 84.375, 81.25, 78.125, 81.25, 75.0, 81.25, 78.125, 78.125, 87.5, 78.125, 71.875, 62.5, 96.875, 75.0, 78.125, 84.375, 78.125, 84.375, 71.875, 75.0, 78.125, 71.875, 93.75, 81.25, 87.5, 87.5, 75.0, 87.5, 71.875, 81.25, 84.375, 78.125, 84.375, 87.5, 90.625, 81.25, 87.5, 75.0, 84.375, 87.5, 84.375, 78.125, 87.5]}